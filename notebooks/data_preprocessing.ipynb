{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8019933d",
   "metadata": {},
   "source": [
    "# Part 1 - Data Handling and Preprocessing\n",
    "## Intelligent Customer Feedback Analysis System\n",
    "\n",
    "**Objective:** Clean and preprocess 1,000+ customer feedback records\n",
    "\n",
    "**Tasks:**\n",
    "- Load and explore the dataset\n",
    "- Remove duplicates and special characters\n",
    "- Tokenization, lemmatization, stopword removal\n",
    "- Handle missing or noisy data\n",
    "- Save cleaned dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a6000a",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c91d308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Text processing\n",
    "import re\n",
    "import string\n",
    "\n",
    "# NLP libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "print(\"‚úì All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b4f40c",
   "metadata": {},
   "source": [
    "## 2. Download NLTK Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f17b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download required NLTK data\n",
    "nltk_resources = ['punkt', 'stopwords', 'wordnet', 'averaged_perceptron_tagger', 'omw-1.4']\n",
    "\n",
    "for resource in nltk_resources:\n",
    "    try:\n",
    "        nltk.download(resource, quiet=True)\n",
    "        print(f\"‚úì Downloaded: {resource}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Error downloading {resource}: {e}\")\n",
    "\n",
    "print(\"\\n‚úì NLTK resources ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c06815",
   "metadata": {},
   "source": [
    "## 3. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112b26d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../dataset/dataset.csv')\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"Total records: {len(df):,}\")\n",
    "print(f\"Total features: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac3f6ad",
   "metadata": {},
   "source": [
    "## 4. Initial Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7e6109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"First 5 rows of the dataset:\\n\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e42033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset info\n",
    "print(\"Dataset Information:\\n\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16bd098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"Statistical Summary:\\n\")\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3713e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values Analysis:\\n\")\n",
    "missing_data = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing Count': df.isnull().sum().values,\n",
    "    'Missing Percentage': (df.isnull().sum().values / len(df) * 100).round(2)\n",
    "})\n",
    "missing_data = missing_data[missing_data['Missing Count'] > 0]\n",
    "\n",
    "if len(missing_data) > 0:\n",
    "    print(missing_data)\n",
    "else:\n",
    "    print(\"‚úì No missing values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc84660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f\"\\nDuplicate rows: {duplicate_count}\")\n",
    "\n",
    "# Check duplicates based on feedback text\n",
    "duplicate_feedback = df.duplicated(subset=['feedback_text']).sum()\n",
    "print(f\"Duplicate feedback texts: {duplicate_feedback}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f69ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment distribution\n",
    "print(\"\\nSentiment Distribution:\\n\")\n",
    "sentiment_dist = df['sentiment_label'].value_counts()\n",
    "print(sentiment_dist)\n",
    "print(f\"\\nSentiment Percentages:\\n{(df['sentiment_label'].value_counts(normalize=True) * 100).round(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f234c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sentiment distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Count plot\n",
    "df['sentiment_label'].value_counts().plot(kind='bar', ax=axes[0], color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "axes[0].set_title('Sentiment Distribution (Count)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Sentiment', fontsize=12)\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Pie chart\n",
    "df['sentiment_label'].value_counts().plot(kind='pie', ax=axes[1], autopct='%1.1f%%', \n",
    "                                          colors=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "axes[1].set_title('Sentiment Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e974782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feedback length analysis\n",
    "df['feedback_length'] = df['feedback_text'].astype(str).apply(len)\n",
    "df['word_count'] = df['feedback_text'].astype(str).apply(lambda x: len(x.split()))\n",
    "\n",
    "print(\"\\nFeedback Length Statistics:\")\n",
    "print(f\"Average character length: {df['feedback_length'].mean():.2f}\")\n",
    "print(f\"Average word count: {df['word_count'].mean():.2f}\")\n",
    "print(f\"Min word count: {df['word_count'].min()}\")\n",
    "print(f\"Max word count: {df['word_count'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8435abbe",
   "metadata": {},
   "source": [
    "## 5. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068c2918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "print(f\"Original dataset size: {len(df_clean):,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581e5322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Handle missing values\n",
    "print(\"\\n=== Step 1: Handling Missing Values ===\")\n",
    "\n",
    "# Drop rows where feedback_text is missing\n",
    "before_drop = len(df_clean)\n",
    "df_clean = df_clean.dropna(subset=['feedback_text'])\n",
    "after_drop = len(df_clean)\n",
    "\n",
    "print(f\"Rows dropped due to missing feedback_text: {before_drop - after_drop}\")\n",
    "\n",
    "# Fill missing sentiment labels with 'neutral' (if any)\n",
    "if df_clean['sentiment_label'].isnull().sum() > 0:\n",
    "    df_clean['sentiment_label'].fillna('neutral', inplace=True)\n",
    "    print(\"Filled missing sentiment labels with 'neutral'\")\n",
    "\n",
    "# Convert all feedback to string\n",
    "df_clean['feedback_text'] = df_clean['feedback_text'].astype(str)\n",
    "\n",
    "print(f\"‚úì Current dataset size: {len(df_clean):,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34137e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Remove duplicates\n",
    "print(\"\\n=== Step 2: Removing Duplicates ===\")\n",
    "\n",
    "before_dedup = len(df_clean)\n",
    "\n",
    "# Remove exact duplicate rows\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "\n",
    "# Remove duplicate feedback texts (keep first occurrence)\n",
    "df_clean = df_clean.drop_duplicates(subset=['feedback_text'], keep='first')\n",
    "\n",
    "after_dedup = len(df_clean)\n",
    "\n",
    "print(f\"Duplicate rows removed: {before_dedup - after_dedup}\")\n",
    "print(f\"‚úì Current dataset size: {len(df_clean):,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c3d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Remove very short feedback (less than 3 words)\n",
    "print(\"\\n=== Step 3: Removing Short/Invalid Feedback ===\")\n",
    "\n",
    "before_filter = len(df_clean)\n",
    "df_clean['temp_word_count'] = df_clean['feedback_text'].apply(lambda x: len(str(x).split()))\n",
    "df_clean = df_clean[df_clean['temp_word_count'] >= 3]\n",
    "df_clean = df_clean.drop('temp_word_count', axis=1)\n",
    "after_filter = len(df_clean)\n",
    "\n",
    "print(f\"Short feedback removed (< 3 words): {before_filter - after_filter}\")\n",
    "print(f\"‚úì Current dataset size: {len(df_clean):,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ce8c46",
   "metadata": {},
   "source": [
    "## 6. Text Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28068140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lemmatizer and stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define text cleaning function\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean text by:\n",
    "    - Converting to lowercase\n",
    "    - Removing URLs, emails, mentions\n",
    "    - Removing special characters and numbers\n",
    "    - Removing extra whitespace\n",
    "    \"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove email addresses\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "    # Remove mentions and hashtags\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def tokenize_text(text):\n",
    "    \"\"\"\n",
    "    Tokenize text into words\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tokens = word_tokenize(text)\n",
    "        return tokens\n",
    "    except:\n",
    "        return text.split()\n",
    "\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    \"\"\"\n",
    "    Remove stopwords from tokenized text\n",
    "    \"\"\"\n",
    "    return [word for word in tokens if word not in stop_words and len(word) > 2]\n",
    "\n",
    "\n",
    "def lemmatize_tokens(tokens):\n",
    "    \"\"\"\n",
    "    Lemmatize tokens\n",
    "    \"\"\"\n",
    "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Complete preprocessing pipeline:\n",
    "    1. Clean text\n",
    "    2. Tokenize\n",
    "    3. Remove stopwords\n",
    "    4. Lemmatize\n",
    "    \"\"\"\n",
    "    # Clean\n",
    "    text = clean_text(text)\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = tokenize_text(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    \n",
    "    # Lemmatize\n",
    "    tokens = lemmatize_tokens(tokens)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "print(\"‚úì Text preprocessing functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed09091",
   "metadata": {},
   "source": [
    "## 7. Test Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2321f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with sample text\n",
    "sample_text = df_clean['feedback_text'].iloc[0]\n",
    "\n",
    "print(\"Original Text:\")\n",
    "print(sample_text)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"After Cleaning:\")\n",
    "cleaned = clean_text(sample_text)\n",
    "print(cleaned)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"After Tokenization:\")\n",
    "tokens = tokenize_text(cleaned)\n",
    "print(tokens)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"After Removing Stopwords:\")\n",
    "no_stopwords = remove_stopwords(tokens)\n",
    "print(no_stopwords)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"After Lemmatization:\")\n",
    "lemmatized = lemmatize_tokens(no_stopwords)\n",
    "print(lemmatized)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"Complete Preprocessing:\")\n",
    "preprocessed = preprocess_text(sample_text)\n",
    "print(preprocessed)\n",
    "print(f\"\\nProcessed tokens: {' '.join(preprocessed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728a5099",
   "metadata": {},
   "source": [
    "## 8. Apply Preprocessing to Entire Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90100d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting text preprocessing...\\n\")\n",
    "print(\"This may take a few minutes for large datasets...\\n\")\n",
    "\n",
    "# Apply cleaning\n",
    "print(\"Step 1/4: Cleaning text...\")\n",
    "df_clean['cleaned_text'] = df_clean['feedback_text'].apply(clean_text)\n",
    "print(\"‚úì Text cleaning completed!\\n\")\n",
    "\n",
    "# Apply tokenization\n",
    "print(\"Step 2/4: Tokenizing text...\")\n",
    "df_clean['tokens'] = df_clean['cleaned_text'].apply(tokenize_text)\n",
    "print(\"‚úì Tokenization completed!\\n\")\n",
    "\n",
    "# Remove stopwords\n",
    "print(\"Step 3/4: Removing stopwords...\")\n",
    "df_clean['tokens_no_stopwords'] = df_clean['tokens'].apply(remove_stopwords)\n",
    "print(\"‚úì Stopwords removal completed!\\n\")\n",
    "\n",
    "# Lemmatize\n",
    "print(\"Step 4/4: Lemmatizing tokens...\")\n",
    "df_clean['lemmatized_tokens'] = df_clean['tokens_no_stopwords'].apply(lemmatize_tokens)\n",
    "print(\"‚úì Lemmatization completed!\\n\")\n",
    "\n",
    "# Create processed text column (tokens joined back into string)\n",
    "df_clean['processed_text'] = df_clean['lemmatized_tokens'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"‚úì ALL PREPROCESSING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1c6ff2",
   "metadata": {},
   "source": [
    "## 9. Post-Preprocessing Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba655958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare before and after\n",
    "print(\"Comparison of Original vs Processed Text:\\n\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Original: {df_clean.iloc[i]['feedback_text'][:150]}...\")\n",
    "    print(f\"Processed: {df_clean.iloc[i]['processed_text'][:150]}...\")\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940aaf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token count statistics\n",
    "df_clean['token_count'] = df_clean['lemmatized_tokens'].apply(len)\n",
    "\n",
    "print(\"\\nToken Count Statistics (After Preprocessing):\")\n",
    "print(f\"Average tokens per feedback: {df_clean['token_count'].mean():.2f}\")\n",
    "print(f\"Min tokens: {df_clean['token_count'].min()}\")\n",
    "print(f\"Max tokens: {df_clean['token_count'].max()}\")\n",
    "print(f\"Median tokens: {df_clean['token_count'].median():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a71722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize token distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df_clean['token_count'], bins=50, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Token Counts', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Number of Tokens', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.axvline(df_clean['token_count'].mean(), color='red', linestyle='--', label=f'Mean: {df_clean[\"token_count\"].mean():.2f}')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(df_clean['token_count'], vert=True)\n",
    "plt.title('Token Count Box Plot', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Number of Tokens', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd814f62",
   "metadata": {},
   "source": [
    "## 10. Create Final Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd92430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns for final dataset\n",
    "final_columns = [\n",
    "    'id',\n",
    "    'source',\n",
    "    'date',\n",
    "    'feedback_text',           # Original text\n",
    "    'cleaned_text',            # Cleaned text\n",
    "    'processed_text',          # Fully processed text\n",
    "    'lemmatized_tokens',       # List of tokens\n",
    "    'rating',\n",
    "    'sentiment_label',\n",
    "    'token_count',\n",
    "    'word_count',\n",
    "    'feedback_length'\n",
    "]\n",
    "\n",
    "# Create final dataset\n",
    "df_final = df_clean[final_columns].copy()\n",
    "\n",
    "# Reset index\n",
    "df_final = df_final.reset_index(drop=True)\n",
    "\n",
    "print(f\"Final cleaned dataset shape: {df_final.shape}\")\n",
    "print(f\"Total records: {len(df_final):,}\")\n",
    "print(f\"\\nColumns in final dataset:\")\n",
    "for i, col in enumerate(df_final.columns, 1):\n",
    "    print(f\"{i}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e892524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample of final dataset\n",
    "print(\"\\nSample of Final Cleaned Dataset:\\n\")\n",
    "df_final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ede1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final data quality check\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL DATA QUALITY REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n1. Dataset Size: {len(df_final):,} records\")\n",
    "print(f\"2. Missing Values: {df_final.isnull().sum().sum()}\")\n",
    "print(f\"3. Duplicate Records: {df_final.duplicated().sum()}\")\n",
    "print(f\"\\n4. Sentiment Distribution:\")\n",
    "print(df_final['sentiment_label'].value_counts())\n",
    "print(f\"\\n5. Average Feedback Length: {df_final['feedback_length'].mean():.2f} characters\")\n",
    "print(f\"6. Average Word Count: {df_final['word_count'].mean():.2f} words\")\n",
    "print(f\"7. Average Token Count (processed): {df_final['token_count'].mean():.2f} tokens\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úì DATA CLEANING AND PREPROCESSING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c2147a",
   "metadata": {},
   "source": [
    "## 11. Save Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06da78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned dataset to CSV\n",
    "output_path = '../dataset/cleaned_customer_feedback.csv'\n",
    "\n",
    "# Convert tokens list to string for CSV storage\n",
    "df_to_save = df_final.copy()\n",
    "df_to_save['lemmatized_tokens'] = df_to_save['lemmatized_tokens'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Save to CSV\n",
    "df_to_save.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úì Cleaned dataset saved to: {output_path}\")\n",
    "print(f\"‚úì File size: {len(df_to_save):,} records\")\n",
    "print(f\"‚úì Columns saved: {len(df_to_save.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4c5369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also save a minimal version for model training\n",
    "df_minimal = df_final[['id', 'processed_text', 'sentiment_label', 'rating']].copy()\n",
    "minimal_path = '../dataset/cleaned_feedback_minimal.csv'\n",
    "df_minimal.to_csv(minimal_path, index=False)\n",
    "\n",
    "print(f\"\\n‚úì Minimal dataset saved to: {minimal_path}\")\n",
    "print(f\"‚úì Columns: {list(df_minimal.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a55b52e",
   "metadata": {},
   "source": [
    "## 12. Summary Statistics and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2742a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive summary visualization\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Sentiment Distribution\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "sentiment_counts = df_final['sentiment_label'].value_counts()\n",
    "colors = ['#FF6B6B' if s == 'negative' else '#4ECDC4' if s == 'positive' else '#45B7D1' \n",
    "          for s in sentiment_counts.index]\n",
    "bars = ax1.bar(sentiment_counts.index, sentiment_counts.values, color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax1.set_title('Sentiment Distribution in Cleaned Dataset', fontsize=16, fontweight='bold', pad=20)\n",
    "ax1.set_xlabel('Sentiment', fontsize=12)\n",
    "ax1.set_ylabel('Count', fontsize=12)\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{int(height):,}\\n({height/len(df_final)*100:.1f}%)',\n",
    "             ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "# 2. Word Count Distribution\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "ax2.hist(df_final['word_count'], bins=40, color='#95E1D3', edgecolor='black')\n",
    "ax2.set_title('Word Count Distribution', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Words', fontsize=10)\n",
    "ax2.set_ylabel('Frequency', fontsize=10)\n",
    "ax2.axvline(df_final['word_count'].mean(), color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "# 3. Token Count Distribution\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "ax3.hist(df_final['token_count'], bins=40, color='#F38181', edgecolor='black')\n",
    "ax3.set_title('Token Count Distribution (After Processing)', fontsize=12, fontweight='bold')\n",
    "ax3.set_xlabel('Tokens', fontsize=10)\n",
    "ax3.set_ylabel('Frequency', fontsize=10)\n",
    "ax3.axvline(df_final['token_count'].mean(), color='blue', linestyle='--', linewidth=2)\n",
    "\n",
    "# 4. Character Length Distribution\n",
    "ax4 = fig.add_subplot(gs[1, 2])\n",
    "ax4.hist(df_final['feedback_length'], bins=40, color='#AA96DA', edgecolor='black')\n",
    "ax4.set_title('Character Length Distribution', fontsize=12, fontweight='bold')\n",
    "ax4.set_xlabel('Characters', fontsize=10)\n",
    "ax4.set_ylabel('Frequency', fontsize=10)\n",
    "ax4.axvline(df_final['feedback_length'].mean(), color='orange', linestyle='--', linewidth=2)\n",
    "\n",
    "# 5. Rating Distribution\n",
    "ax5 = fig.add_subplot(gs[2, 0])\n",
    "df_final['rating'].value_counts().sort_index().plot(kind='bar', ax=ax5, color='#FCBAD3', edgecolor='black')\n",
    "ax5.set_title('Rating Distribution', fontsize=12, fontweight='bold')\n",
    "ax5.set_xlabel('Rating', fontsize=10)\n",
    "ax5.set_ylabel('Count', fontsize=10)\n",
    "ax5.tick_params(axis='x', rotation=0)\n",
    "\n",
    "# 6. Sentiment by Rating\n",
    "ax6 = fig.add_subplot(gs[2, 1:])\n",
    "sentiment_rating = pd.crosstab(df_final['rating'], df_final['sentiment_label'])\n",
    "sentiment_rating.plot(kind='bar', stacked=True, ax=ax6, \n",
    "                      color=['#FF6B6B', '#45B7D1', '#4ECDC4'], edgecolor='black')\n",
    "ax6.set_title('Sentiment Distribution by Rating', fontsize=12, fontweight='bold')\n",
    "ax6.set_xlabel('Rating', fontsize=10)\n",
    "ax6.set_ylabel('Count', fontsize=10)\n",
    "ax6.legend(title='Sentiment', fontsize=9)\n",
    "ax6.tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.suptitle('Data Preprocessing Summary - Part 1 Complete', \n",
    "             fontsize=18, fontweight='bold', y=0.995)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bd2158",
   "metadata": {},
   "source": [
    "## 13. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88778f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"#\"*100)\n",
    "print(\"#\" + \" \"*98 + \"#\")\n",
    "print(\"#\" + \" \"*30 + \"PART 1 - DATA HANDLING COMPLETED\" + \" \"*35 + \"#\")\n",
    "print(\"#\" + \" \"*98 + \"#\")\n",
    "print(\"#\"*100)\n",
    "\n",
    "print(\"\\nüìä DELIVERABLES:\")\n",
    "print(\"   ‚úì Cleaned dataset with 1,000+ records\")\n",
    "print(\"   ‚úì Data preprocessing notebook (this file)\")\n",
    "print(\"   ‚úì Removed duplicates and special characters\")\n",
    "print(\"   ‚úì Performed tokenization, lemmatization, stopword removal\")\n",
    "print(\"   ‚úì Handled missing and noisy data\")\n",
    "\n",
    "print(\"\\nüìÅ OUTPUT FILES:\")\n",
    "print(\"   1. ../dataset/cleaned_customer_feedback.csv (Full cleaned dataset)\")\n",
    "print(\"   2. ../dataset/cleaned_feedback_minimal.csv (Minimal for training)\")\n",
    "\n",
    "print(\"\\nüìà DATASET STATISTICS:\")\n",
    "print(f\"   ‚Ä¢ Total Records: {len(df_final):,}\")\n",
    "print(f\"   ‚Ä¢ Features: {len(df_final.columns)}\")\n",
    "print(f\"   ‚Ä¢ Sentiments: {df_final['sentiment_label'].nunique()} classes\")\n",
    "print(f\"   ‚Ä¢ Average Tokens: {df_final['token_count'].mean():.2f}\")\n",
    "print(f\"   ‚Ä¢ Data Quality: 100% (No missing values, No duplicates)\")\n",
    "\n",
    "print(\"\\n‚úÖ READY FOR PART 2: Sentiment Classification Model\")\n",
    "print(\"\\n\" + \"#\"*100 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
